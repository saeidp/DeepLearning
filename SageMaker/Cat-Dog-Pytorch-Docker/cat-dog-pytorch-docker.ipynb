{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you have Separate bash file then run it from this notebook as follows\n",
    "\n",
    "`!sh test.sh`\n",
    "\n",
    "#### Running your notebook needs special credentials which you can create it at the start of creating notebook instance\n",
    "\n",
    "* AmazonSageMakerFullAccess\n",
    "* AmazonEc2ContainerRegisteryFullAccess\n",
    "* AmazonS3FullAccess\n",
    "\n",
    "It is not mandatory to add amazon s3 full access you can add policy just as follows \n",
    "\n",
    "`{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:DeleteObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}`\n",
    "\n",
    "### The following codes work as follows:\n",
    "* creates docker image and push that to ECR\n",
    "* Assigns the S3 path for training data\n",
    "* Gets the role this notebook is running on\n",
    "* Creates the estimator\n",
    "\n",
    "\n",
    "* `Please make sure to use your ECR docker image name`\n",
    "* `This code assumes docker image is running in region ap-southeast-2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torchnet as tnt\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=pytorch-extending-our-containers-cat-dog-example\n",
    "\n",
    "cd container\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-ap-southeast-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "echo fullname\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Get the login command from ECR in order to pull down the SageMaker PyTorch image\n",
    "$(aws ecr get-login --registry-ids 520713654638 --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} . --build-arg REGION=${region}\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = 'saeid-cat-dog'\n",
    "\n",
    "outputpath='s3://saeid-cat-dog/output'\n",
    "training_path = 's3://saeid-cat-dog/data'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecr_image = \"243524247240.dkr.ecr.ap-southeast-2.amazonaws.com/pytorch-extending-our-containers-cat-dog-example:latest\"\n",
    "from sagemaker.estimator import Estimator\n",
    "hyperparameters = {\n",
    "    \n",
    "                        'batch_size': 16,\n",
    "                        'lr': 0.01,\n",
    "                        'lr_step': 10,\n",
    "                        'data_location':training_path,\n",
    "                        'epochs':5,\n",
    "                        'mean': [0.485, 0.456, 0.406],\n",
    "                        'std':[0.229, 0.224, 0.225],\n",
    "                        'no_of_classes':2,             \n",
    "                        'model_def':'resnet50'\n",
    "                    }\n",
    "\n",
    "\n",
    "estimator = Estimator(role=role,\n",
    "                      image_name=ecr_image,\n",
    "                      base_job_name='docker-resnet50-cat-dog',\n",
    "                      output_path=outputpath,\n",
    "                      train_instance_count=1,\n",
    "                      train_instance_type='ml.p3.2xlarge',\n",
    "                      train_max_run=(5*24*60*60),\n",
    "                      train_volume_size=20,\n",
    "                      hyperparameters=hyperparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({'training': training_path})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
